plot(NULL, xlim=c(1,N), ylim=c(1,3))
for(i in 2:N){ points(i, fibonacci_ratio(i)) }
# -----------------------------------
# Task 02, 03
# -----------------------------------
N = 30
plot(NULL, xlim=c(1,N), ylim=c(1,3))
fibonacci_ratio(2)
# -----------------------------------
# Task 02, 03
# -----------------------------------
N = 30
plot(NULL, xlim=c(1,N), ylim=c(1,3))
for(i in 3:N){ points(i, fibonacci_ratio(i)) }
fibonacci_ratio(3)
i=3
points(i, fibonacci_ratio(i))
fibonacci_ratio(i)
i
plot(NULL, xlim=c(1,N), ylim=c(1,3))
points(i, fibonacci_ratio(i))
# -----------------------------------
# Task 02, 03
# -----------------------------------
N = 30
plot(NULL, xlim=c(1,N), ylim=c(1,3))
points(i, fibonacci_ratio(i), add=T)
# -----------------------------------
# Task 02, 03
# -----------------------------------
N = 30
i = 1:N
fib_ratio = data.frame(i, ratio=fibonacci_ratio(i))
fib_ratio
fibonacci_ratio(i)
apply(i, fibonacci_ratio)
sapply(i, fibonacci_ratio)
lapply(i, fibonacci_ratio)
apply(i, 1, fibonacci_ratio)
sapply(i, fibonacci_ratio, simplify = T)
for(j in i){ fibonacci_ratio(j) }
fib_ratio = data.frame(i, ratio=for(j in i){ fibonacci_ratio(j) } )
for(j in i){ fibonacci_ratio(j) }
i
fibonacci_ratio(j)
for(j in i){ fibonacci_ratio(j) }
ratio = for(j in i){ fibonacci_ratio(j) }
ratio
fib_ratio = data.frame(i=1:N)
fib_ratio
fibonacci_ratio(fib_ratio$i)
apply(fib_ratio$i, 1, fibonacci_ratio)
apply(fib_ratio, 1, fibonacci_ratio)
apply(fib_ratio, 1, fibonacci_ratio)[1]
apply(fib_ratio, 1, fibonacci_ratio)[[1]]
apply(fib_ratio, 1, fibonacci_ratio)[1:N]
apply(fib_ratio, 1, fibonacci_ratio)[1]
apply(fib_ratio, 1, fibonacci_ratio)[[]][1]
apply(fib_ratio, 1, fibonacci_ratio)[[1:N]][1]
apply(fib_ratio, 1, fibonacci_ratio)[1:N][1]
unlist(apply(fib_ratio, 1, fibonacci_ratio) )
fib_ratio$ratio = c(NA, ratio)
plot(fib_ratio, xlim=c(1,N), ylim=c(1,3))
fib_ratio
# -----------------------------------
# Task 02, 03
# -----------------------------------
N = 30
fib_ratio = data.frame(i=1:N)
ratio = unlist( apply(fib_ratio, 1, fibonacci_ratio) )
ratio
fib_ratio$ratio = c(NA, ratio)
plot(fib_ratio, xlim=c(1,N), ylim=c(1,3))
plot(fib_ratio, xlim=c(1,N), ylim=c(0.5,2.5), type='l')
# -----------------------------------
# Task 02, 03
# -----------------------------------
N = 50
fib_ratio = data.frame(i=1:N)
ratio = unlist( apply(fib_ratio, 1, fibonacci_ratio) )
fib_ratio$ratio = c(NA, ratio)
plot(fib_ratio, xlim=c(1,N), ylim=c(0.5,2.5), type='l')
print('N = 7: ', fibonacci_seq(7) )
print( paste0('N = 7: ', fibonacci_seq(7) ) )
print( paste0('N = 7: ', paste0( fibonacci_seq(7) ) ) )
paste0( fibonacci_seq(7) )
print( paste0('N = 7: ', paste0( fibonacci_seq(7) ) ) )
paste0( fibonacci_seq(7) )
1000 * (1 + returns[1])
# -----------------------------------
# Task 03
# -----------------------------------
returns = c(1.03,0.97,1.41,0.81,0.92,1.03,1.05,2.45,2.31,0.61)
1000 * (1 + returns[1])
1000 * (1 + returns[1]/100)
returns_perc = returns/100
# -----------------------------------
# Task 03
# -----------------------------------
returns = c(1.03,0.97,1.41,0.81,0.92,1.03,1.05,2.45,2.31,0.61)
returns_perc = returns/100
returns_perc
1000 * (1 + returns_perc[1])
1000 * (1 + returns_perc)
main_inv = 1000 * (1 + returns_perc)
main_inv
main_inv[1:9]
main_inv[1:9] * (1 + returns_perc[1:9])
return_year = returns_perc * 1000
return_year
sum(return_year)
sum(return_year)/1000
mean(returns_perc)
sum(return_year)/100
sum(return_year)
sum(return_year)/1000/10
mean(returns_perc)
# investing 1000 only in the first year and leaving it
return_year = c()
return_year = c(return_year, 1000*returns_perc[1])
return_year
return_year[i-1]
i=2
return_year[i-1]
# investing 1000 only in the first year and leaving it
return_year = c()
return_year = c(return_year, 1000*(1 + returns_perc[1]) )
return_year
return_year[i-1]
for(i in 2:10){
return_year = c(return_year, return_year[i-1]*(1 + returns_perc[i]) )
}
return_year
return_year - 1000
(return_year - 1000)/1000/10
return_year - 1000
# investing 1000 only in the first year and leaving it
return_year = c()
return_year = c(return_year, 1000*(1 + returns_perc[1]) )
for(i in 2:10){
return_year = c(return_year, return_year[i-1]*(1 + returns_perc[i]) )
}
return_year
return_year = (return_year - 1000)/1000/10
return_year
mean(returns_perc)
return_year[10]
log(returns_perc)
mean(log(returns_perc))
exp(mean(log(returns_perc)))
mean(return_year)
# investing 1000 only in the first year and leaving it
return_year = c()
return_year = c(return_year, 1000*(1 + returns_perc[1]) )
for(i in 2:10){
return_year = c(return_year, return_year[i-1]*(1 + returns_perc[i]) )
}
return_year
prod( returns_perc )
prod( returns_perc )^(1/10)
file_dir = "/home/jriveraespejo/Desktop/#Classes/4(8)_P0Q00a StatisticsV/exercise/session 02/pokemon.csv"
pokemon = read.csv(file_dir)
str(pokemon)
# preliminar ####
rm(list=ls())
librerias <- c('stringr','dplyr','ggplot2','ggpubr','knitr','tidyverse',
'reshape2','tinytex','gt','haven',
'dagitty','ellipse','mvtnorm','MASS','splines','gtools',
'rethinking','rstan','coda','runjags','rjags','loo')
sapply(librerias, require, character.only=T)
# sapply(librerias, install.packages, character.only=T)
setwd('~/Desktop/project_europa')
# data ####
## load ####
file_dir = '/home/jriveraespejo/Desktop/project_europa/data/final/8_NLPdata.csv'
wordcloud = read.csv(file_dir)
# str(wordcloud)
# dim(wordcloud)
## prepare ####
# train set
N = nrow(wordcloud)
idx = sample(1:N, size=round(N*0.9))
train = rep(FALSE, N)
train[idx] = TRUE
# sum(train)
data_list = list(N = nrow(wordcloud[train,]),
K = ncol(wordcloud)-1,
G = wordcloud$G[train],
W = as.matrix(wordcloud[train,-251]) )
# str(data_list)
# model ####
mcmc_code <- "
data {
int N;
int K;
int G[N];
matrix[N, K] W;
}
parameters {
vector[K] b;
}
model {
vector[N] v; // linear predictor
vector[N] p; // probability
// priors
b ~ double_exponential(0, 0.2); // LASSO prior (highly regularizing)
//b ~ normal(0, 0.2); // highly regularizing prior (not LASSO)
// model
v = W * b;
p = inv_logit(v);
G ~ bernoulli(p);
}
"
save_code = file.path('notebooks', "wordcloud_model.stan" )
writeLines( mcmc_code, con=save_code)
mcmc_model <- stan( file=save_code, data=data_list, chains=4, cores=4)
# results ####
results = precis( mcmc_model, dept=2 )
rownames(results) = names(wordcloud)[-251]
round( results[order(results$mean, decreasing = F),], 2 )
round( results[order(results$mean, decreasing = T),], 2 )
PSIS(mcmc_model)
mcmc_model <- stan( file=save_code, data=data_list, chains=4, cores=4, log_lik=T)
mcmc_code <- "
data {
int N;
int K;
int G[N];
matrix[N, K] W;
}
parameters {
vector[K] b;
}
model {
vector[N] v; // linear predictor
vector[N] p; // probability
// priors
b ~ double_exponential(0, 0.2); // LASSO prior (highly regularizing)
//b ~ normal(0, 0.2); // highly regularizing prior (not LASSO)
// model
v = W * b;
p = inv_logit(v);
G ~ bernoulli(p);
}
generated quantities{
vector[N] v; // linear predictor
vector[N] p; // probability
vector[N] log_lik; // log-likelihood
// non vectorized form
v = W * b;
p = inv_logit(v);
for(i in 1:N){
log_lik[i] = bernoulli_lpmf(G[i] | p[i]);
}
}
"
save_code = file.path('notebooks', "wordcloud_model.stan" )
writeLines( mcmc_code, con=save_code)
mcmc_model <- stan( file=save_code, data=data_list, chains=4, cores=4)
# results ####
results = precis( mcmc_model, dept=2, omit='log_lik' )
rownames(results) = names(wordcloud)[-251]
str(results)
results
idx_names = str_detect( rownames(results), 'log_lik')
sum(idx_names)
rownames(results)
idx_names = str_detect( rownames(results), '^b')
sum(idx_names)
results = results[idx_names, ]
rownames(results) = names(wordcloud)[-251]
# parameters
round( results[order(results$mean, decreasing = F),], 2 )
round( results[order(results$mean, decreasing = T),], 2 )
# parameters
round( head( results[order(results$mean, decreasing = F),], 20) , 2 )
round( head( results[order(results$mean, decreasing = T),], 20), 2 )
# fit
WAIC(mcmc_model)
PSIS(mcmc_model)
PSIS(mcmc_model, pointwise = T)
PSIS_res = PSIS(mcmc_model, pointwise=T)
PSIS_res[ order(PSIS_res$k, decreasing = T) ]
PSIS_res[ order(PSIS_res$k, decreasing = T), ]
head( PSIS_res[ order(PSIS_res$k, decreasing = T), ], 10)
# posterior predictive ####
post = extract.samples(mcmc_model)
str(post)
post = post$b
post
apply(post, 2, mean)
pars_mu = apply(post, 2, mean)
pars_CI = apply(post, 2, PI, 0.95)
pars_mu
pars_CI
W_test = as.matrix(wordcloud[!train,-251])
W_test
v = W_test %*% pars_mu
v
p = inv_logit(v)
p
W_test
G_test = wordcloud$G[!train]
G_test
caret::confusionMatrix(G_test, p>=0.5)
install.packages('caret')
caret::confusionMatrix(G_test, p>=0.5)
table(G_test, p>=0.5)
table(G_test, integer(p>=0.5))
p = as.integer( inv_logit(v) >= 0.5)
table(G_test, p)
str(pars_CI)
str(pars_CI[1,])
v = W_test %*% pars_CI[1,]
v
p = as.integer( inv_logit(v) >= 0.5)
table(G_test, p)
v = W_test %*% t(pars_CI[1,])
dim(W_test)
dim(pars_CI[1,])
dim(pars_CI)
dim(t(pars_CI))
v = W_test %*% t(pars_CI)
v
inv_logit(v)
p = as.integer( inv_logit(v) >= 0.5)
p
inv_logit(v) >= 0.5
p = apply( inv_logit(v) >= 0.5, 2, as.integer)
p
table(G_test, p[,1])
table(G_test, p[,2])
table(G_test, p)
# posterior predictive ####
G_test = wordcloud$G[!train]
W_test = as.matrix(wordcloud[!train,-251])
post = extract.samples(mcmc_model)
post = post$b
pars_mu = apply(post, 2, mean)
pars_CI = apply(post, 2, PI, 0.95)
v = W_test %*% pars_mu
p = as.integer( inv_logit(v) >= 0.5)
table(G_test, p)
v = W_test %*% t(pars_CI)
p = apply( inv_logit(v) >= 0.5, 2, as.integer)
table(G_test, p[,1])
table(G_test, p[,2])
mcmc_code <- "
data {
int N;
int K;
int G[N];
matrix[N, K] W;
}
parameters {
vector[K] b;
}
model {
vector[N] v; // linear predictor
vector[N] p; // probability
// hyper prior
sigma_b ~ exponential(3);
// priors
// multilevel LASSO prior (highly regularizing),
b ~ double_exponential(0, sigma_b);
//# // highly regularizing prior (not LASSO, not multilevel)
//# b ~ normal(0, 0.2);
// model
v = W * b;
p = inv_logit(v);
G ~ bernoulli(p);
}
generated quantities{
vector[N] v; // linear predictor
vector[N] p; // probability
vector[N] log_lik; // log-likelihood
// model
v = W * b;
p = inv_logit(v);
for(i in 1:N){
log_lik[i] = bernoulli_lpmf(G[i] | p[i]);
}
}
"
save_code = file.path('notebooks', "wordcloud_model.stan" )
writeLines( mcmc_code, con=save_code)
mcmc_model <- stan( file=save_code, data=data_list, chains=4, cores=4)
mcmc_code <- "
data {
int N;
int K;
int G[N];
matrix[N, K] W;
}
parameters {
real<lower=0> sigma_b;
vector[K] b;
}
model {
vector[N] v; // linear predictor
vector[N] p; // probability
// hyper prior
sigma_b ~ exponential(3);
// priors
// multilevel LASSO prior (highly regularizing),
b ~ double_exponential(0, sigma_b);
//# // highly regularizing prior (not LASSO, not multilevel)
//# b ~ normal(0, 0.2);
// model
v = W * b;
p = inv_logit(v);
G ~ bernoulli(p);
}
generated quantities{
vector[N] v; // linear predictor
vector[N] p; // probability
vector[N] log_lik; // log-likelihood
// model
v = W * b;
p = inv_logit(v);
for(i in 1:N){
log_lik[i] = bernoulli_lpmf(G[i] | p[i]);
}
}
"
save_code = file.path('notebooks', "wordcloud_model.stan" )
writeLines( mcmc_code, con=save_code)
mcmc_model <- stan( file=save_code, data=data_list, chains=4, cores=4)
# results ####
results = precis( mcmc_model, dept=2 )
idx_names = str_detect( rownames(results), '^sigma_b')
results[idx_names, ]
mcmc_code <- "
data {
int N;
int K;
int G[N];
matrix[N, K] W;
}
parameters {
vector[K] b;
}
model {
vector[N] v; // linear predictor
vector[N] p; // probability
// priors
// multilevel LASSO prior (highly regularizing),
b ~ double_exponential(0, 0.2);
//# // highly regularizing prior (not LASSO, not multilevel)
//# b ~ normal(0, 0.2);
// model
v = W * b;
p = inv_logit(v);
G ~ bernoulli(p);
}
generated quantities{
vector[N] v; // linear predictor
vector[N] p; // probability
vector[N] log_lik; // log-likelihood
// model
v = W * b;
p = inv_logit(v);
for(i in 1:N){
log_lik[i] = bernoulli_lpmf(G[i] | p[i]);
}
}
"
save_code = file.path('notebooks', "wordcloud_model.stan" )
writeLines( mcmc_code, con=save_code)
mcmc_model <- stan( file=save_code, data=data_list, chains=4, cores=4)
## load ####
file_dir = '/home/jriveraespejo/Desktop/project_europa/data/final/8_NLPdata.csv'
wordcloud = read.csv(file_dir)
str(wordcloud)
dim(wordcloud)
# results ####
results = precis( mcmc_model, dept=2 )
idx_names = str_detect( rownames(results), '^b')
results = results[idx_names, ]
rownames(results) = names(wordcloud)[-251]
rownames(results) = names(wordcloud)[-c(251:252)]
# parameters
round( head( results[order(results$mean, decreasing = F),], 20) , 2 )
round( head( results[order(results$mean, decreasing = T),], 20), 2 )
# fit
WAIC(mcmc_model)
PSIS_res = PSIS(mcmc_model, pointwise=T)
head( PSIS_res[ order(PSIS_res$k, decreasing = T), ], 10)
company_names = wordcloud[train, 'Name']
company_names
company_names[c(385, 388, 389, 391, 396, 397)]
company_names = wordcloud[train, 'Name']
company_names[c(385, 388, 389, 391, 396, 397)]
company_names[idx_outlier]
idx_outlier = c(385, 388, 389, 391, 396, 397)
company_names[idx_outlier]
data_list$W[idx_outlier,]
rowSums( data_list$W[idx_outlier,] )
idx_outlier
rowSums( data_list$W[idx_outlier,] )
company_names[idx_outlier]
# fit and outliers
WAIC(mcmc_model)
PSIS_res = PSIS(mcmc_model, pointwise=T)
PSIS_res
# fit and outliers
WAIC(mcmc_model)
PSIS(mcmc_model)
rowSums( data_list$W[idx_outlier,] )
v = W_test %*% pars_mu
p = as.integer( inv_logit(v) >= 0.5)
table(G_test, p)
